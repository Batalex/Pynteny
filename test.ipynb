{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, you gotta redo the filtering strategy, it's wrong to filter by pairs, this way gene pairs may be isolated (of course)\n",
    "\n",
    "# e.g.,\n",
    "\n",
    "# 2955  HF571520.1_1897__HF571520.1_1897_1878235_18794...  HF571520.1_1897  HF571520.1     1897  (1878235, 1879485)    pos\n",
    "# The above was hit of 899.1\n",
    "# 1271  HF571520.1_1898__HF571520.1_1898_1879706_18817...  HF571520.1_1898  HF571520.1     1898  (1879706, 1881700)    neg\n",
    "# This one hit of 171.1 and 170.1\n",
    "\n",
    "\n",
    "# 899: 1897 (pos)\n",
    "# 171: 411, 1898\n",
    "# 170: 410, 1898\n",
    "\n",
    "\n",
    "# Solutions:\n",
    "\n",
    "\"\"\"\n",
    "1. Sort hmmer hits by contig name, perhaps use a dictionary. Perhaps add tag to label containing hmm name\n",
    "2. Search for hits within the same contig that satisfy the structure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pynteny.utils import readFromPickleFile\n",
    "from pynteny.filter import LabelParser\n",
    "\n",
    "\n",
    "hmm_hits = readFromPickleFile(\"/home/robaina/Documents/Pynteny/hmm_hits.pickle\")\n",
    "\n",
    "hmm_order = [\"TIGR00899.1\", \"TIGR00171.1\", \"TIGR00170.1\", \"TIGR00973.1\"]\n",
    "n_hmms = len(hmm_order)\n",
    "hmm_order_dict = dict(zip(hmm_order, range(n_hmms)))\n",
    "\n",
    "hit_labels = {}\n",
    "labelparser = LabelParser()\n",
    "for hmm, hits in hmm_hits.items():\n",
    "    labels = hits.id.values.tolist()\n",
    "    if not labels:\n",
    "        raise ValueError(\n",
    "            f'No records found in database matching HMM: {hmm}'\n",
    "            )\n",
    "    hit_labels[hmm] = labelparser.parse_from_list(labels)\n",
    "    hit_labels[hmm][\"hmm\"] = hmm\n",
    "\n",
    "\n",
    "\n",
    "# Create single dataframe with new column corresponding to HMM and all hits\n",
    "all_hit_labels = pd.concat(hit_labels.values()).groupby(\"contig\").filter(lambda x : len(x) >= n_hmms).sort_values([\"contig\", \"gene_pos\"])  # remove contigs with less hits than the number of hmms in synteny structure\n",
    "all_hit_labels[\"gene_pos_diff\"] = all_hit_labels.gene_pos.diff()\n",
    "\n",
    "# Drop sequences hit by more than one hmm\n",
    "all_hit_labels = all_hit_labels.drop_duplicates(subset=all_hit_labels.columns.difference([\"hmm\", \"gene_pos_diff\"]), keep=False)\n",
    "\n",
    "# Reset index\n",
    "all_hit_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add HMM codes\n",
    "all_hit_labels[\"hmm_code\"] = all_hit_labels.hmm.apply(lambda hmm: hmm_order_dict[hmm])\n",
    "\n",
    "\n",
    "# Strand in integers\n",
    "all_hit_labels[\"strand\"] = all_hit_labels.strand.apply(lambda strand: -1 if strand == \"neg\" else 1)\n",
    "\n",
    "contig_names = all_hit_labels.contig.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_order_pattern = [\"TIGR00899.1\", \"TIGR00171.1\"]\n",
    "hmm_code_order_pattern = [0, 1] # \"TIGR00899.1\", \"TIGR00171.1\" # list(hmm_order_dict.values())\n",
    "strand_order_pattern = [0, 0] #,0, 0]\n",
    "distance_order_pattern = [100] #, 0, 1]\n",
    "\n",
    "\n",
    "def contains_hmm_pattern(data: pd.Series) -> int:\n",
    "    return 1 if data.values.tolist() == hmm_code_order_pattern else 0\n",
    "\n",
    "def contains_distance_pattern(data: pd.Series) -> int:\n",
    "    return 1 if all(\n",
    "        [   (data_dist <= pattern_dist and data_dist > 0)\n",
    "            for data_dist, pattern_dist in zip(data.values.tolist()[1:], distance_order_pattern)\n",
    "            ]\n",
    "        ) else 0\n",
    "\n",
    "def contains_strand_pattern(data: pd.Series) -> int:\n",
    "    strand_comparisons = []\n",
    "    for data_strand, pattern_strand in zip(data.values, strand_order_pattern):\n",
    "        if pattern_strand != 0:\n",
    "            strand_comparisons.append(data_strand == pattern_strand)\n",
    "        else:\n",
    "            strand_comparisons.append(True)\n",
    "    return 1 if all(strand_comparisons) == True else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynteny.filter import LabelParser\n",
    "\n",
    "# hmm_order = [\"TIGR00171.1\", \"TIGR00170.1\"] #[\"TIGR00899.1\", \"TIGR00171.1\", \"TIGR00170.1\", \"TIGR00973.1\"]\n",
    "# hmm_order_dict = dict(zip(hmm_order, [1, 2]))\n",
    "\n",
    "output_file = \"results.tsv\"\n",
    "\n",
    "n_hmms = len(hmm_order_pattern)\n",
    "output_lines = []\n",
    "\n",
    "for contig in contig_names:\n",
    "\n",
    "    synteny_hits = []\n",
    "    contig_hits = all_hit_labels[all_hit_labels.contig == contig].reset_index(drop=True)\n",
    "\n",
    "    if set(hmm_order_pattern) == set(contig_hits.hmm.unique()):\n",
    "        \n",
    "        hmm_match = contig_hits.hmm_code.rolling(window=n_hmms).apply(contains_hmm_pattern)\n",
    "        strand_match = contig_hits.strand.rolling(window=n_hmms).apply(contains_strand_pattern)\n",
    "        distance_match = contig_hits.gene_pos_diff.rolling(window=n_hmms).apply(contains_distance_pattern)\n",
    "\n",
    "        matched_rows = contig_hits[\n",
    "            (hmm_match == 1) &\n",
    "            (strand_match == 1) &\n",
    "            (distance_match == 1)\n",
    "        ]\n",
    "        \n",
    "        for i, row in matched_rows.iterrows():\n",
    "            matched_hits = contig_hits.iloc[i - (n_hmms -1): i + 1]\n",
    "            for label, hmm in zip(matched_hits.full.values, matched_hits.hmm):\n",
    "                parsed_label = LabelParser.parse(label)\n",
    "                synteny_hits.append(\n",
    "                     (\n",
    "                        f\"{parsed_label['contig']}\\t{parsed_label['gene_id']}\\t\"\n",
    "                        f\"{parsed_label['gene_pos']}\\t{parsed_label['locus_pos']}\\t\"\n",
    "                        f\"{parsed_label['strand']}\\t{hmm}\\t{parsed_label['full']}\\n\"\n",
    "                        )\n",
    "                )\n",
    "            output_lines.extend(synteny_hits)\n",
    "\n",
    "\n",
    "\n",
    "with open(output_file, \"w\") as outfile:\n",
    "    outfile.write(\"contig\\tgene_id\\tgene_number\\tlocus\\tstrand\\tHMM\\tfull_label\\n\")\n",
    "    outfile.writelines(output_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">CP000435.1_1__CP000435.1_1_174_1331_pos\n"
     ]
    }
   ],
   "source": [
    "record_name = \"CP000435.1_1 # 174 # 1331 # 1 # ID=1_1;partial=00;start_type=ATG;rbs_motif=None;rbs_spacer=None;gc_cont=0.567\"\n",
    "\n",
    "\n",
    "name_list = record_name.split(\" \")\n",
    "contig = \"_\".join(name_list[0].split(\"_\")[:-1])\n",
    "gene_number = name_list[0].split(\"_\")[-1]\n",
    "start, end = name_list[2], name_list[4]\n",
    "strand = \"pos\" if name_list[6] == \"1\" else \"neg\"\n",
    "\n",
    "\n",
    "header = f\">{contig}_{gene_number}__{contig}_{gene_number}_{start}_{end}_{strand}\"\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from pynteny.utils import fullPathListDir\n",
    "\n",
    "for file in fullPathListDir(\"/home/robaina/Databases/MarRef_1.7/prodigal\"):\n",
    "    if '.gbk' in file:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynteny.preprocessing import parseProdigalOutput, mergeFASTAs\n",
    "\n",
    "\n",
    "# mergeFASTAs(\n",
    "#     \"/home/robaina/Databases/MarRef_1.7/prodigal\",\n",
    "#     output_fasta=\"/home/robaina/Databases/MarRef_1.7/marref_prodigal.faa\"\n",
    "# )\n",
    "\n",
    "parseProdigalOutput(\n",
    "    prodigal_faa=\"/home/robaina/Databases/MarRef_1.7/marref_prodigal.faa\",\n",
    "    output_file=\"/home/robaina/Databases/MarRef_1.7/marref_prodigal_longlabels.faa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO, SeqRecord\n",
    "\n",
    "\n",
    "file = \"/home/robaina/Documents/Pynteny/MG1655.gb\"\n",
    "file = \"/home/robaina/Databases/MarRef_1.7/prodigal/marref.gbk\"\n",
    "file = \"/home/robaina/Documents/Pynteny/BACL149.gbk\"\n",
    "gbk_contigs = list(SeqIO.parse(file, 'genbank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SeqRecord(seq=Seq('ATCAACACCCAGTTTTTTCCAAGGTAAGTTTTCTGGATCGCTTTCGTGAAAACA...GCC'), id='1', name='1', description='Genus species strain strain', dbxrefs=[])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbk_contig = gbk_contigs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynteny.preprocessing import assignGeneLocationToRecords\n",
    "\n",
    "\n",
    "\n",
    "gbk_file = \"/home/robaina/Documents/Pynteny/MG1655.gb\"\n",
    "\n",
    "assignGeneLocationToRecords(\n",
    "    gbk_file=gbk_file,\n",
    "    output_fasta=None,\n",
    "    nucleotide=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynteny.wrappers import runProdigal\n",
    "\n",
    "# Run prodigal on assembly to obtain gene translation and positional info\n",
    "\n",
    "runProdigal(\n",
    "    input_file=\"genome_assembly.fasta\",\n",
    "    output_prefix=None,\n",
    "    output_dir=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of split genomes, each part comes in a different gbk file,this would happen with differnt contigs as well.\n",
    "# So, basically, I only need the gbk file, which can be obtanined from prokka with the genome assembly in fasta format.\n",
    "# Genes appear to be sorted by loci in gbk files\n",
    "# Actually, the departing point for a hmmer search with synteny info would be a fasta file containing reference sequences...\n",
    "# so, we would need to obtain these sequences from the gbk file or map them somehow?\n",
    "# Perhaps better to store positional info in a dict, this way no need to alter contig/sequence names\n",
    "\n",
    "from Bio import SeqIO, SeqRecord\n",
    "\n",
    "\n",
    "file = \"/home/robaina/Documents/Pynteny/MG1655.gb\"\n",
    "\n",
    "\n",
    "gbk_contigs = list(SeqIO.parse(gbk_file, 'genbank'))\n",
    "\n",
    "with open(\"LongLabels.fasta\", \"w\") as outfile:\n",
    "\n",
    "    for gbk_contig in gbk_contigs:\n",
    "        \n",
    "        gene_counter = 0\n",
    "        for feature in gbk_contig.features:\n",
    "\n",
    "            if \"cds\" in feature.type.lower():\n",
    "                \n",
    "                name = feature.qualifiers[\"locus_tag\"][0].replace('_', '.')\n",
    "                start, end, strand = str(feature.location.start), str(feature.location.end), feature.location.strand\n",
    "                start = start.replace(\">\", \"\").replace(\"<\", \"\")\n",
    "                end = end.replace(\">\", \"\").replace(\"<\", \"\")\n",
    "                strand_sense = \"neg\" if strand == -1 else \"pos\"\n",
    "\n",
    "                header = f\">{name}__{gbk_contig.name.replace('_', '')}_{gene_counter}_{start}_{end}_{strand_sense}\\n\"\n",
    "                if \"translation\" in feature.qualifiers:\n",
    "                    translation = feature.qualifiers[\"translation\"][0]\n",
    "\n",
    "                    header = f\">{name}__{gbk_contig.name.replace('_', '')}_{gene_counter}_{start}_{end}_{strand_sense}\\n\"\n",
    "                    outfile.write(header)\n",
    "                    outfile.write(translation + \"\\n\")\n",
    "\n",
    "                    gene_counter += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "367a058ebb24ea2c2bb1633bf810ec6a1a05f59e065f27f721ea93103e797079"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('traits')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
